{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install recogym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood based models\n",
    "\n",
    "This notebook will outline the likelihood based approach to training on Bandit feedback.\n",
    "\n",
    "Although before proceeding we will study the output of the simulator in a little more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from recogym import verify_agents\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "from recogym.evaluate_agent import verify_agents, plot_verify_agents\n",
    "\n",
    "import gym, recogym\n",
    "from copy import deepcopy\n",
    "from recogym import env_1_args\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = [6, 3]\n",
    "\n",
    "num_users = 5000\n",
    "num_products = 10\n",
    "num_samples = 20\n",
    "\n",
    "env_1_args['phi_var'] = 0.0\n",
    "env_1_args['number_of_flips'] = 0\n",
    "env_1_args['sigma_mu_organic'] = 0.0\n",
    "env_1_args['sigma_omega'] = 1\n",
    "env_1_args['random_seed'] = 42\n",
    "env_1_args['num_products'] = num_products\n",
    "env_1_args['K'] = 5\n",
    "env_1_args['number_of_flips'] = 5\n",
    "\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(env).generate_logs(num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn Data into Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to build a _Logistic Regression_ model.\n",
    "\n",
    "The model will predict _the probability of the click_ for the following data:\n",
    "* _`Views`_ is a total amount of views of a particular _`Product`_ shown during _Organic_ _`Events`_ **before** a _Bandit_ _`Event`_.\n",
    "* _`Action`_ is a proposed _`Product`_ at a _Bandit_ _`Event`_.\n",
    "\n",
    "For example, assume that we have _`10`_ products. In _Organic_ _`Events`_, these products  were shown to a user as follows:\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Product ID</th>\n",
    "        <th>Views</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>0</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>1</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>2</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>3</td>\n",
    "        <td>7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>4</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>5</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>6</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>7</td>\n",
    "        <td>8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>8</td>\n",
    "        <td>11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>9</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "When we want to know the probability of the click for _`Product`_ = _`8`_ with available amounts of _`Views`_, the input data for the model will be:\n",
    "\n",
    "_`0 0 0 7 0 0 0 0 8 11 0`_ _**`8`**_\n",
    "\n",
    "The first 10 numbers are _`Views`_ of _`Products`_ (see above), the latest one is the _`Action`_.\n",
    "\n",
    "The output will be two numbers:\n",
    "* $0^{th}$ index: $1 - \\mathbb{P}_c(P=p|V)$.\n",
    "* $1^{st}$ index: $\\mathbb{P}_c(P=p|V)$.\n",
    "\n",
    "Here, $\\mathbb{P}_c(P=p|V)$ is the probability of the click for a _`Product`_ $p$, provided that we have _`Views`_ $V$.\n",
    "\n",
    "\n",
    "We will of course encode _`Action`_ using one hot encoding.\n",
    "In our current example, the _`Action`_ is _`8`_. Thus, it is encoded as:\n",
    "\n",
    "_`0 0 0 0 0 0 0 0`_ _**`1`**_ _`0`_\n",
    "\n",
    "Here,\n",
    "* Vector of _`Actions`_ has a size that is equal to the _*number of `Products`*_ i.e. _`10`_.\n",
    "* _`Action`_ _`8`_ is marked as _`1`_ (_`Action`_ starts with _`0`_).\n",
    "\n",
    "To build the final feature vector, we need to cross features from `Views` with `Action`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents import FeatureProvider\n",
    "\n",
    "class CountFeatureProvider(FeatureProvider):\n",
    "    \"\"\"Feature provider as an abstract class that defined interface of setting/getting features\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(CountFeatureProvider, self).__init__(config)\n",
    "        self.feature_data = np.zeros((self.config.num_products))\n",
    "\n",
    "    def observe(self, observation):\n",
    "        \"\"\"Consider an Organic Event for a particular user\"\"\"\n",
    "        for session in observation.sessions():\n",
    "            self.feature_data[int(session['v'])] += 1\n",
    "\n",
    "    def features(self, observation):\n",
    "        \"\"\"Provide feature values adjusted to a particular feature set\"\"\"\n",
    "        return self.feature_data\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_data = np.zeros((self.config.num_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from recogym import Configuration, DefaultContext, Observation\n",
    "from recogym.envs.session import OrganicSessions\n",
    "\n",
    "def build_train_data(logs, feature_provider):\n",
    "    user_states, actions, rewards, proba_actions = [], [], [], []\n",
    "    \n",
    "    current_user = None\n",
    "    for _, row in logs.iterrows():\n",
    "        if current_user != row['u']:\n",
    "            # Use has changed: start a new session and reset user state\n",
    "            current_user = row['u']\n",
    "            sessions = OrganicSessions()\n",
    "            feature_provider.reset()\n",
    "        \n",
    "        context = DefaultContext(row['u'], row['t'])\n",
    "        \n",
    "        if row['z'] == 'organic':\n",
    "            sessions.next(context, row['v'])\n",
    "            \n",
    "        else:\n",
    "            # For each bandit event, generate one observation for the user state, the taken action\n",
    "            # the obtained reward and the used probabilities\n",
    "            feature_provider.observe(Observation(context, sessions))\n",
    "            user_states.append(feature_provider.features(None))\n",
    "            actions.append(row['a'])\n",
    "            rewards.append(row['c'])\n",
    "            proba_actions.append(row['ps'])\n",
    "            \n",
    "            # Start a new organic session\n",
    "            sessions = OrganicSessions()\n",
    "    \n",
    "    return np.array(user_states), np.array(actions).astype(int), np.array(rewards), np.array(proba_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now see data that will be provided to our agents based on logistic regressions\n",
    "config = Configuration(env_1_args)\n",
    "count_feature_provider = CountFeatureProvider(config=config)\n",
    "\n",
    "user_states, actions, rewards, proba_actions = build_train_data(data, count_feature_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_start, preview_size = 500, 3\n",
    "\n",
    "print('user product views count at action time')\n",
    "print(user_states[preview_start:preview_start + preview_size])\n",
    "print('taken actions', actions[preview_start:preview_start + preview_size])\n",
    "print('obtained rewards', rewards[preview_start:preview_start + preview_size])\n",
    "print('probablities of the taken actions', proba_actions[preview_start:preview_start + preview_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data and see how it maps into the features - which is the combination of the history and the actions and the label which is clicks.  Note that only the bandit events correspond to records in the training data.\n",
    "\n",
    "In order to do personalisation it is necessary to cross the action and history features. _Why_?  We do the simplest possible cross an element wise kronecker product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodAgent(Agent):\n",
    "    def __init__(self, feature_provider, use_argmax=False, seed=43):\n",
    "        self.feature_provider = feature_provider\n",
    "        self.use_argmax = use_argmax\n",
    "        self.random_state = RandomState(seed)\n",
    "        self.model = None\n",
    "        \n",
    "    @property\n",
    "    def num_products(self):\n",
    "        return self.feature_provider.config.num_products\n",
    "    \n",
    "    def _create_features(self, user_state, action):\n",
    "        \"\"\"Create the features that are used to estimate the expected reward from the user state.\n",
    "        \"\"\"\n",
    "        features = np.zeros(len(user_state) * self.num_products)\n",
    "        features[action * len(user_state): (action + 1) * len(user_state)] = user_state\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train(self, logs):\n",
    "        user_states, actions, rewards, proba_actions = build_train_data(logs, self.feature_provider)\n",
    "        \n",
    "        features = np.vstack([\n",
    "            self._create_features(user_state, action) \n",
    "            for user_state, action in zip(user_states, actions)\n",
    "        ])\n",
    "        self.model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "        self.model.fit(features, rewards)\n",
    "    \n",
    "    def _score_products(self, user_state):\n",
    "        all_action_features = np.array([\n",
    "            self._create_features(user_state, action) \n",
    "            for action in range(self.num_products)\n",
    "        ])\n",
    "        return self.model.predict_proba(all_action_features)[:, 1]\n",
    "        \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past history\"\"\"\n",
    "        self.feature_provider.observe(observation)        \n",
    "        user_state = self.feature_provider.features(observation)\n",
    "        prob = self._score_products(user_state)\n",
    "        \n",
    "        if not self.use_argmax:\n",
    "            action = self.random_state.choice(self.num_products, p=(prob / np.sum(prob)))\n",
    "            ps = prob[action]\n",
    "            all_ps = prob.copy()\n",
    "        else:\n",
    "            action = np.argmax(prob)\n",
    "            ps = 1.0\n",
    "            all_ps = np.zeros(self.num_products)\n",
    "            all_ps[action] = 1.0\n",
    "      \n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'expected-value': prob[action],\n",
    "                'ps': ps,\n",
    "                'ps-a': all_ps,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_provider.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the feature vector used by the Likelihood agent\n",
    "picked_sample = 500\n",
    "\n",
    "count_product_views_feature_provider = CountFeatureProvider(config)\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider)\n",
    "\n",
    "print('User state', user_states[picked_sample])\n",
    "print('action', actions[picked_sample])\n",
    "print('Created cross features')\n",
    "print(likelihood_logreg._create_features(user_states[picked_sample], actions[picked_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider, use_argmax=True)\n",
    "likelihood_logreg.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({\n",
    "            **organic_user_count_args,\n",
    "            **env_1_args,\n",
    "            'select_randomly': True,\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = verify_agents(env, \n",
    "                       number_of_users = 5000, \n",
    "                       agents = {\n",
    "                           'likelihood logreg': likelihood_logreg, \n",
    "                           'organic count': organic_counter_agent\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_verify_agents(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and retrieval\n",
    "\n",
    "Now to illustrate the use of embeddings and then a nearest neighbour retrieval approach, we are going to use organic data, build a matrix of product coviews by the same user, and factorize this matrix with an SVD to get product embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def create_embeddings(data, num_products, embedding_size=5):\n",
    "    organic_events = data[data['z'] == 'organic']\n",
    "    print(\"num organic events\", len(organic_events))\n",
    "\n",
    "    n_users = data['u'].nunique()\n",
    "    counts = np.zeros((n_users, num_products))\n",
    "    print(\"num users\", n_users)\n",
    "\n",
    "    binarizer = LabelBinarizer().fit(np.arange(num_products))\n",
    "    for u in range(n_users):\n",
    "        binarized_views_of_user = binarizer.transform(organic_events[organic_events['u'] == u]['v'])\n",
    "        counts[u, :] = binarized_views_of_user.sum(axis=0)\n",
    "\n",
    "    counts_above_zero = 1. * (counts > 0)  # above zero counts only\n",
    "    co_counts = np.matmul(counts_above_zero.T, counts_above_zero)\n",
    "    print(\"Coview matrix shape\", co_counts.shape)\n",
    "\n",
    "    embeddings = TruncatedSVD(embedding_size).fit_transform(co_counts)\n",
    "    print(\"Embeddings shape\", embeddings.shape)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = create_embeddings(data, num_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "class RetrievalAgent(Agent):\n",
    "    def __init__(self, env, feature_provider, product_embeddings):\n",
    "        # Set environment as an attribute of Agent.\n",
    "        self.env = env\n",
    "        self.feature_provider = feature_provider\n",
    "        self.product_embeddings = product_embeddings\n",
    "        self.num_products = self.product_embeddings.shape[0]\n",
    "        self.embeddings_index = spatial.KDTree(self.product_embeddings)\n",
    "        self.reset()\n",
    "        \n",
    "    def build_user_embedding(self, user_state):\n",
    "        return np.average(self.product_embeddings, axis=0, weights=user_state)\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past history\"\"\"\n",
    "        self.feature_provider.observe(observation)\n",
    "        user_embedding = self.build_user_embedding(self.feature_provider.features(observation))\n",
    "        closest_product = self.embeddings_index.query(user_embedding)[1]\n",
    "        scores = np.zeros(self.num_products)\n",
    "        scores[closest_product] = 1.0\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': closest_product,\n",
    "                'ps': 1.,\n",
    "                'ps-a': scores,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_provider.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_agent(env_args, embeddings):\n",
    "    config = Configuration(env_args)\n",
    "    retrieval_agent = RetrievalAgent(\n",
    "        config,\n",
    "        CountFeatureProvider(config),\n",
    "        embeddings)\n",
    "    \n",
    "    return retrieval_agent\n",
    "\n",
    "retrieval_agent = build_retrieval_agent(env_1_args, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = verify_agents(env, \n",
    "                       number_of_users = 5000, \n",
    "                       agents = {\n",
    "                           'likelihood logreg': likelihood_logreg, \n",
    "                           'organic count': organic_counter_agent,\n",
    "                           'retrieval_agent': retrieval_agent\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_verify_agents(result)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
